<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://matano.dev/blog-archive</id>
    <title>Matano Blog</title>
    <updated>2022-03-09T00:00:00.000Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://matano.dev/blog-archive"/>
    <subtitle>Matano Blog</subtitle>
    <icon>https://matano.dev/img/favicon.svg</icon>
    <entry>
        <title type="html"><![CDATA[How we build a fully regional cloud architecture on AWS]]></title>
        <id>/2022/03/09/regional-cloud-architecture</id>
        <link href="https://matano.dev/blog-archive/2022/03/09/regional-cloud-architecture"/>
        <updated>2022-03-09T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[How we've built a fully regional cloud infrastructure on AWS at Apptrail.]]></summary>
        <content type="html"><![CDATA[<p>At least for me, building on the cloud gives often gives me unexpected joy. To think that I can deploy servers in Bahrain or Japan from my couch is still something I get excited about!</p><p>At Apptrail, we run completely on the cloud, specifically AWS, and one of the main reasons is how easy it is to launch services in new geographical regions. We deploy our services to independent cloud regions and provide our customers with regional endpoints (e.g. <code>events.us-west-2.apptrail.com</code>).</p><p>Here are some of our learnings from building a fully regional service on AWS.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="what-are-cloud-regions">What are cloud regions?<a class="hash-link" href="#what-are-cloud-regions" title="Direct link to heading">​</a></h2><p>Cloud providers have a concept of regions for their cloud. These are isolated geographical regions where their physical infrastructure is hosted and where they offer cloud services. For example, at the time of this article, AWS offers 26 different cloud regions. Software applications built on the cloud can leverage cloud regions to also build a concept of regions in their applications to improve their services.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="cellular-architecture">Cellular architecture<a class="hash-link" href="#cellular-architecture" title="Direct link to heading">​</a></h3><p>To understand regionality, it's good to understand <em>cellular architecture</em>. Cellular (or cell-based) architecture is a way of separating systems into isolated <em>cells</em> to reduce the blast radius from something going wrong. The idea is that a failure shouldn't ever cross cells, and so cellularization is a way of creating those independent partitions. The actual method of choosing a cell can be anything, from random based on ID to logical like geographical region. You can also have nested cells for further isolation (e.g. <em>Large volume customers in US West region</em> could be a particular cell). AWS Availability zones, for example, are also sub-regional cells. All in all, cellularization is a very powerful way of designing available systems, you can <a href="https://www.youtube.com/watch?v=swQbA4zub20" target="_blank" rel="noopener noreferrer">learn more about it here</a>.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="why-regions-exist">Why regions exist<a class="hash-link" href="#why-regions-exist" title="Direct link to heading">​</a></h3><p>Regions, then, are just cells that are based on geographical region. Regions serve several purposes. From an availability and reliability perspective, regions are at the center of a cloud's reliability strategy. In a cellular architecture, regions serve as the first and most principal cells. They ensure that there is a logical containment of resources that are isolated from others. This helps prevent widespread outages.</p><p>Regions do refer to actual geographic regions, so this is also an important part of why they exist. One benefit of this is latency. Providing a way for customers to ensure that their workloads run in a particular region helps them with running workloads close to their customers.</p><p>Another important usecase is compliance and data sovereignty. Many countries are passing legislation requiring user data and other sensitive data to be physically stored in locations under their jurisdiction. Cloud regions are a way to ensure compliance with such regulations.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="multi-region-architectures">Multi region architectures<a class="hash-link" href="#multi-region-architectures" title="Direct link to heading">​</a></h2><p>Because cloud providers do the hard work of making sure all their services are available in isolated regions, one benefit customers get is being able to run multi region workloads. Multi region architecture is a way to get another layer of reliability beyond multi availability zone. You can, for example, run a load balanced service across multiple regions using Route 53 for latency based routing and health check based failover. One can also use regions for data preservation and backup, e.g. with Amazon S3. Region wide outages are pretty rare at AWS so active multi region for services is likely overkill (as it may also come with downsides like cross region data transfer), but everyone has their availability requirements and multi region architectures are a powerful tool to leverage for increased availability.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="regionalized-architectures">Regionalized architectures<a class="hash-link" href="#regionalized-architectures" title="Direct link to heading">​</a></h2><p>A regionalized architecture is one where the regionality is part of the interface of the service. For example, in regional architectures, one has dedicated regional endpoints that clients use for each supported region. Each regional service in a regional architecture should be independent of other instances running in other regions.</p><p>As an example, say we have an image processing API. Our clients use this API to upload, process, and retrieve videos. To regionalize this API, we can deploy the API to multiple regions and offer endpoints like <code>region1.videoapi.example.com</code> and <code>region2.videoapi.example.com</code> for our clients to use.</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="difference-between-multi-region-and-regionalized-architectures">Difference between multi region and regionalized architectures<a class="hash-link" href="#difference-between-multi-region-and-regionalized-architectures" title="Direct link to heading">​</a></h4><div class="cntr"><p><img loading="lazy" src="/assets/images/regional-diagram-ef9b5ea0c5dec022647f24f931252019.png" width="1168" height="461" class="img_ev3q"></p><p><em>Comparison between regional (left) and multi region architectures</em></p></div><p>The key difference between multi region and regionalized architectures is that in regional architectures, the region is part of the contract of the service, whereas in multi region architectures it is solely part of the implementation. In a multi region architecture, regions are used as cells for increased availability or as a failover. There is no guarantee that a specific customer's requests will run in a specific region. Rather, the customer doesn't even have to know about the concept of region vis-à-vis the service. In a regional architecture, however, the region is part of the public API, and customers choose or are informed of the region they are associated with.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="choosing-regions-for-a-regional-architecture">Choosing regions for a regional architecture<a class="hash-link" href="#choosing-regions-for-a-regional-architecture" title="Direct link to heading">​</a></h3><p>When building a regionalized architecture, one needs to pick a list of geographical regions to support and a methodology to assign them. You're likely deployed on a cloud, so a simple decision is to choose your regions to correspond to cloud regions. This is <a href="https://apptrail.com/docs/applications/guide/regions" target="_blank" rel="noopener noreferrer">what we do at Apptrail</a>, for example. One can rename them, or just use the same names, which is what we do at Apptrail ourselves.</p><p>However, a one-to-one mapping is not necessary. You can also come up with regions that correspond to multiple cloud regions. For example, a region structure could look as follows:</p><div class="cntr"><table><thead><tr><th align="center">Region</th><th align="center">AWS Region(s)</th></tr></thead><tbody><tr><td align="center">us</td><td align="center">us-east-1, us-west-2, us-east-2</td></tr><tr><td align="center">eu</td><td align="center">eu-west-1, eu-west-2</td></tr><tr><td align="center">jp</td><td align="center">ap-northeast-1, ap-northeast-2</td></tr><tr><td align="center">in</td><td align="center">ap-south-1, ap-south-2</td></tr></tbody></table><p><em>Regionalization scheme using multi region cells</em></p></div><p>Such a scheme gives one some benefit of each application region consisting of multiple cloud regions, which can improve availability.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="when-to-use-a-regional-architecture">When to use a regional architecture<a class="hash-link" href="#when-to-use-a-regional-architecture" title="Direct link to heading">​</a></h2><p>Most services likely don't need to be fully regionalized. Unlike multi-regionality, which is solely a technical engineering decision, choosing to regionalize your public APIs or services is more so a product decision. It should generally serve some need or purpose for your customer. We observe common usecases:</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="data-residency-requirements">Data residency requirements<a class="hash-link" href="#data-residency-requirements" title="Direct link to heading">​</a></h4><p>Regionalization of your services is a way of allowing your customers to ensure their data is stored and processed in a specific region. This is often requested due to regulatory reasons.</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="latency">Latency<a class="hash-link" href="#latency" title="Direct link to heading">​</a></h4><p>For other applications, minimizing client latency is highly important. Keeping requests in the region closest to a customer is a way to achieve this. However, as keeping requests in region is not inherently a strict requirement, complete regionalization may or may not be the correct approach here, as a single endpoint with latency based routing may also fulfill the requirements. The desired experience of the customer is important to consider here (e.g. do you want your customer to have to think of regions?).</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="choosing-components-to-regionalize">Choosing components to regionalize<a class="hash-link" href="#choosing-components-to-regionalize" title="Direct link to heading">​</a></h2><p>When evaluating a regional architecture, a natural question is what components to regionalize. Specifically, which services to have a publicly regional interface for. There are several considerations here, and the answer goes back to why one is using a regional architecture in the first place. A useful heuristic we use is one between <em>control planes</em> and <em>data planes</em>. Generally, control plane services shouldn't be regional, but dataplane services can be. To understand why, we may consider the common actions we do in the control plane: e.g. billing, user management, or other global configuration. These often have single region dependencies and are relatively infrequent. For us, it's neither important nor desirable to have these be regionalized. On the other hand, our data plane processes that process and store important data are regionalized.</p><p>Note that while this is a general guideline that we ourselves have found useful, it's in no way prescriptive. There are many cases where one may make the control plane regionalized as well. In general, the reason for regionalization should be central to this decision. One should consider how regionalizing a service will help or prevent them from achieving that goal.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="how-we-deploy-to-many-regions">How we deploy to many regions<a class="hash-link" href="#how-we-deploy-to-many-regions" title="Direct link to heading">​</a></h2><p>Infrastructure and deployment automation is key to being able to maintain consistency, reliability, and understandability while deploying many services across different regions. Thankfully, infrastructure as code solutions, particularly the AWS CDK, make this much easier.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="staged-deployment-using-waves">Staged deployment using Waves<a class="hash-link" href="#staged-deployment-using-waves" title="Direct link to heading">​</a></h3><p>We use a concept of <em>waves</em> when deploying software at Apptrail. Going back to cellular architecture, a wave is essentially a set of cells to deploy to concurrently. For example, currently, our waves are:</p><div class="cntr"><table><thead><tr><th align="center">Wave</th><th align="center">Apptrail Regions</th></tr></thead><tbody><tr><td align="center">Wave 1</td><td align="center">ap-south-1</td></tr><tr><td align="center">Wave 2</td><td align="center">eu-west-1</td></tr><tr><td align="center">Wave 3</td><td align="center">us-west-2, us-east-1</td></tr></tbody></table><p><em>Our current waves at Apptrail</em></p></div><p>Deploying to one wave at a time ensures that faulty changes don't cause global outages. Combined with bake times (adding wait times between waves to monitor for degradation) and automated rollbacks, waves can help ensure that you don't have catastrophic failures. We've found them to be very useful for staging our changes. You can <a href="https://aws.amazon.com/builders-library/automating-safe-hands-off-deployments/" target="_blank" rel="noopener noreferrer">learn more about waves here</a>.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="infrastructure-as-code---cdk">Infrastructure as Code - CDK<a class="hash-link" href="#infrastructure-as-code---cdk" title="Direct link to heading">​</a></h3><p>Completely automating your infrastructure is essential when deploying to many regions since one is duplicating one's entire application and services each time they deploy to a new region. We use the AWS CDK to help us do this. CDK is a wrapper around CloudFormation that lets you write your infrastructure as real code (e.g. we use Typescript). It makes building reusable abstractions (called <em>constructs</em>) as easy as writing a class or a function (<a href="https://docs.aws.amazon.com/cdk/v2/guide/home.html" target="_blank" rel="noopener noreferrer">Learn more about it here</a>, we think it's one of the coolest things AWS offers!).</p><p>The CDK also comes with useful high level abstractions out of the box, so you don't have to reinvent the wheel.</p><div class="cntr"><p><img loading="lazy" src="/assets/images/apptrail-waves-ffbffb671a220d613cf67fdf09505129.png" width="563" height="418" class="img_ev3q"></p><p><em>A pipeline deploying one of our regional services to one of our waves</em></p></div><p>For example, we use <a href="https://aws.amazon.com/blogs/developer/cdk-pipelines-continuous-delivery-for-aws-cdk-applications" target="_blank" rel="noopener noreferrer">CDK Pipelines</a> for deploying all of our infrastructure at Apptrail. In CDK Pipelines, stages and <em>waves</em> are supported natively so you can easily deploy cellular applications. At Apptrail, we've developed a standard <em>Pipeline</em> construct that sets up our standard waves and makes creating a regionalized service conforming to Apptrail regions and waves very simple.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="other-considerations-around-regional-architectures">Other considerations around regional architectures<a class="hash-link" href="#other-considerations-around-regional-architectures" title="Direct link to heading">​</a></h2><p>Here are some other things we've learned building regional applications on AWS.</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="use-separate-aws-accounts-per-region">Use separate AWS accounts per region<a class="hash-link" href="#use-separate-aws-accounts-per-region" title="Direct link to heading">​</a></h4><p>This is general AWS best practice but reinforces thinking of each instance of a service deployed in a region as separate with clearly delineated blast radiuses.</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="managing-cost">Managing cost<a class="hash-link" href="#managing-cost" title="Direct link to heading">​</a></h4><p>Regionalization inherently comes with some additional cost. However, when an application is architected correctly, the additional cost due to regionalization should mainly be a fixed cost per region, which is generally negligible at scale. Regionalized services shouldn't generally have excessive have cross-region data transfer (databases and other global data is often the exception, but this should be low cost).</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="global-data">Global data<a class="hash-link" href="#global-data" title="Direct link to heading">​</a></h4><p>A common consideration when evaluating a regionalized or multi region architecture is what to do with global data. There's no one answer here. Keeping in mind our earlier discussion on choosing components to regionalize and data planes &amp; control planes, there are several ways we could deal with this. For example, we could keep global data in one control plane region, and our regionalized data plane services can depend on this control plane. This is what we use ourselves at Apptrail. However, this may or may not be acceptable. If latency is the primary motivation for regionalization, then this is less than ideal. There are several ways to deal with this, including DynamoDB Global Tables and database replication, that are beyond the scope of this article (see this <a href="https://www.youtube.com/watch?v=2e29I3dA8o4" target="_blank" rel="noopener noreferrer">video</a> for some more information). On the other hand, if the main reason for regionalization is data residency, and our control plane only stores non-sensitive configuration, then this is a more fitting approach.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="conclusion">Conclusion<a class="hash-link" href="#conclusion" title="Direct link to heading">​</a></h2><p>As it gets easier and easier to deploy to the cloud, and with increased concern about data sovereignty, regional architectures are becoming more common. This gave you an overview of how we easily maintain our regional services on AWS at Apptrail. You might not need regionalization for your next project, but I hope this was helpful and informative.</p><p><em>What do you think of regionalization, do you use it in your applications? Feel free to reply.</em></p>]]></content>
        <author>
            <name>Samrose Ahmed</name>
            <email>samrose@matano.dev</email>
            <uri>https://matano.dev</uri>
        </author>
        <category label="engineering" term="engineering"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[The difference between internal and customer facing audit logs]]></title>
        <id>/2022/03/07/internal-vs-customer-facing-audit-logs</id>
        <link href="https://matano.dev/blog-archive/2022/03/07/internal-vs-customer-facing-audit-logs"/>
        <updated>2022-03-07T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[A look at the two different types of audit logs and why internally stored and externally surfaced audit logs are different.]]></summary>
        <content type="html"><![CDATA[<p>As a software company, you likely store audit logs internally for debugging, security, and compliance. But can your customers access these audit logs self service?</p><p>Learn about the difference between storing audit logs internally and offering your customers self service access to their own audit logs.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="what-are-audit-logs">What are audit logs?<a class="hash-link" href="#what-are-audit-logs" title="Direct link to heading">​</a></h2><p>Audit logs are a record of activity in an application. They help answer questions like who, what, where, when, and how a specific action occurred, and what resources it affected. They are used for debugging, security, monitoring, and compliance.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="internal-audit-logs">Internal audit logs<a class="hash-link" href="#internal-audit-logs" title="Direct link to heading">​</a></h2><p>A software company should store audit logs internally as a best practice. They are needed to be for developer debugging and also to be able to answer support questions like what happened during a specific incident. Maintaining audit logs is also required for compliance with common standards like SOC II.</p><p>Internal audit logs are generally stored in log providers like Cloudwatch or DataDog, or object stores like Amazon S3. They are only accessible by employees of the software company, preferably specifically the security or DevOps teams. An employee should be able to query the logs to extract specific data in response to common questions like who performed a specific action.</p><p>In a multitenant SaaS company, each audit log is likely associated with a specific tenant. For example, if we examine an audit log for a DeleteUser operation, the audit log will contain information about which tenant the operation was related to. However, employees generally have access to all tenants' audit logs.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="how-can-a-customer-access-their-audit-logs">How can a customer access their audit logs?<a class="hash-link" href="#how-can-a-customer-access-their-audit-logs" title="Direct link to heading">​</a></h3><p>In a situation where a SaaS company is following best practices and storing audit logs for all actions in their application, how does a customer of the company access audit logs relating to their account? Because the audit logs are internal, not partitioned by tenant, and not accessible except to internal employees, the process for a customer to access their audit logs is manual. A common flow is a customer creates a support ticket, an engineer or support associate queries the internal logs, and posts the information back to the customer in the ticket. Companies often build internal tooling to make this process easier for their employees.</p><div></div><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="disadvantages-of-only-maintaining-internal-audit-logs">Disadvantages of only maintaining internal audit logs<a class="hash-link" href="#disadvantages-of-only-maintaining-internal-audit-logs" title="Direct link to heading">​</a></h4><p>Exclusively storing audit logs internally without offering a way for customers to easily consume those audit logs comes with many drawbacks. The SaaS company is essentially serving as a human proxy to the internal audit logs system. First, it is reactive, meaning the customer can only request their audit logs after an event has occurred, when often they need them most when the event is occurring (or even before to perform security monitoring). Second, the entire process is manual, which wastes both the SaaS company's and customers' time and severely limits the number of audit logs that the customer can request. Thirdly, it prevents customers from being to extract full value out of their audit logs, and keeps customers from having visibility into activity in their account.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="external-or-customer-facing-audit-logs">External, or customer facing, audit logs<a class="hash-link" href="#external-or-customer-facing-audit-logs" title="Direct link to heading">​</a></h2><p>External audit logs are audit logs that the customers of a SaaS product can access self service.</p><p>A key first requirement here, naturally, is that each customer is only able to access their own audit logs and not any other customer's audit logs. This requires storing the audit logs so that they are partitioned by customer. It also requires building an API service that lets authenticated customers query their own logs.</p><p>Such a system allows a SaaS customer to access their audit logs automatedly without needing to involve the SaaS company.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="advantages-of-self-service-audit-logs">Advantages of self service audit logs<a class="hash-link" href="#advantages-of-self-service-audit-logs" title="Direct link to heading">​</a></h3><p>Being able to access audit logs self service opens many usecases for SaaS customers. For example:</p><ul><li>The customer is free to query and retrieve as many audit logs as they want. Ideally, they should be able to continuously export all their audit logs out of the SaaS for analytics, monitoring, or archival.</li><li>Both the SaaS owner and SaaS customer do not need to expend manual effort to exchange audit logs.</li><li>Customers can build proactive security monitoring systems that use audit logs for threat detection, using SIEM or other tools. This allows customers to make realtime use of their audit events.</li></ul><p>In general, externally facing audit logs give SaaS customers full insight into their SaaS activity. This enables them to consume and use SaaS audit logs themselves for security monitoring, auditing, risk management, or any other use that requires audit events.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="when-should-i-use-internal-or-external-audit-logs">When should I use internal or external audit logs?<a class="hash-link" href="#when-should-i-use-internal-or-external-audit-logs" title="Direct link to heading">​</a></h2><p>Internal and external audit logs are not mutually exclusive, rather they are complementary.</p><p>When evaluating using internal or external audit logs, the answer is fairly simple. Every company should maintain internal audit logs. This is a best security practice, and is mandated by compliance standards like SOC 2. It is required for debugging and to be able to answer questions in the case of an incident.</p><p>SaaS companies should also offer their customers a way to access their own audit logs self service. This is the best way to ensure that your customers have the best security posture, and to prevent yourself from having to deal with manual audit requests.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="summary">Summary<a class="hash-link" href="#summary" title="Direct link to heading">​</a></h2><p>To summarize, SaaS companies should store audit logs internally and should also offer a system for their customers to easily access their own audit logs without a manual process. To outline the differences between internal and external audit logs:</p><table><thead><tr><th></th><th align="center">Internal audit logs</th><th align="center">External audit logs</th></tr></thead><tbody><tr><td>Used by</td><td align="center">SaaS company employees</td><td align="center">SaaS customers</td></tr><tr><td>Implementation</td><td align="center">Log providers, object stores</td><td align="center">Custom: API layer + data store or managed (<a href="https://apptrail.com" target="_blank" rel="noopener noreferrer">Apptrail</a>)</td></tr><tr><td>Customer access</td><td align="center">Manual</td><td align="center">Self service</td></tr></tbody></table><p>We can see that internal and external audit logs serve two different purposes and that internal audit logs are not a substitute for external audit logs. Internal audit logs are a baseline measure that lets the <em>employees</em> of a SaaS company audit all API and user activity whereas external, or customer facing, audit logs allow customers to access their own audit logs.</p><p>If you're an engineer or owner working on a SaaS product, keep in mind building externally facing audit logs for your customers.</p>]]></content>
        <author>
            <name>Samrose Ahmed</name>
            <email>samrose@matano.dev</email>
            <uri>https://matano.dev</uri>
        </author>
        <category label="general" term="general"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[S3 POST Policy - The hidden S3 feature you haven't heard of]]></title>
        <id>/2022/02/14/s3-post-policy</id>
        <link href="https://matano.dev/blog-archive/2022/02/14/s3-post-policy"/>
        <updated>2022-02-14T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[A look at S3 POST Policies and how to use them to create secure, short lived client object upload sessions.]]></summary>
        <content type="html"><![CDATA[<p>Say you're building an application and you need to let your users upload files to S3. How would you go about it?</p><p>Particularly, imagine our clients are uploading a lot of files of different sizes, and are sensitive to latency.</p><p>Let's walk through a journey of AWS APIs, and explore a little known feature of S3 called <em>POST Policies</em>.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="presigned-urls">Presigned URLs<a class="hash-link" href="#presigned-urls" title="Direct link to heading">​</a></h2><p>Your immediate instinct may be to use <a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/PresignedUrlUploadObject.html" target="_blank" rel="noopener noreferrer">S3 presigned URLs</a>.
Presigned URLs let you create a URL that you can share and allow a user to download or upload to an S3 bucket. You create the presigned
URL server side using IAM credentials that have the valid S3 permissions and then share the URL to allow user actions. Clients simply use HTTP clients to connect to the URL.
You can set an expiry time to any date time to ensure the access is short lived and you can also attach an IAM policy to the presigned URL to limit the permissions the client has.</p><p>All in all, presigned URLs are pretty powerful and sound like a great choice for allowing credential-less S3 actions. They have one major limitation, however.
<em>S3 presigned upload urls require you to know the Content length before hand.</em> Because of the way presigned URLs work, using AWS4 Signatures, the Content-Length
is a required component when generating the presigned URL. This means we can't return one presigned URL and allow our clients to upload objects of variable size while
it is not expired.</p><p>As a workaround, we can have the client request a presigned URL every time they want to perform an upload. This is not necessarily a big deal, and may
be perfectly suitable for many scenarios.</p><div></div><p>However, this results in an additional call for every upload and may not be desirable. For example, say we want our clients to have a short lived
session where they can upload a large number of objects, and latency is important.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="a-new-api-using-temporary-credentials">A new API using temporary credentials<a class="hash-link" href="#a-new-api-using-temporary-credentials" title="Direct link to heading">​</a></h2><p>Presigned URLs don't seem to work well for our usecase, so let's try a new approach. AWS IAM offers APIs to
<a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_temp_request.html" target="_blank" rel="noopener noreferrer">request temporary security credentials</a>. There's
a few different APIs, but let's see if we can use <a href="https://docs.aws.amazon.com/STS/latest/APIReference/API_AssumeRole.html" target="_blank" rel="noopener noreferrer">AssumeRole</a> to return temporary
credentials to our client.</p><p>As an approach, we can call STS AssumeRole server side and return temporary IAM credentials to our client. We can use IAM <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html#policies_session" target="_blank" rel="noopener noreferrer">session policies</a>
to limit the S3 permissions the client has access to. We can also use the <a href="https://docs.aws.amazon.com/STS/latest/APIReference/API_AssumeRole.html#API_AssumeRole_RequestParameters" target="_blank" rel="noopener noreferrer">DurationSeconds</a>
parameter to limit the validity of the credentials, but only up to a minimum of 15 minutes.</p><p>Our clients would then use the credentials and upload files using the AWS SDK. If we're offering this as a part of our API, we'd likely want to write a language native client
that wraps the AWS SDK and takes care of refereshing the credentials.</p><p>Security-wise, you may feel icky having to return credentials using your API, but the approach is generally sound as long as the credentials are short lived and you are
giving access to authenticated callers with narrow permissions.</p><p>This approach works, but besides having to implement this API, comes with several downsides:</p><ul><li>Dealing with unsigned credentials.</li><li>Our client needs to depend on heavyweight AWS SDKs, rather than a simple HTTP Client.</li><li>We can't control the size of the object our client uploads. This can be a concern with untrusted or semi-trusted clients, who could upload very
large files to our S3 bucket.</li></ul><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="enter-post-policy">Enter POST Policy<a class="hash-link" href="#enter-post-policy" title="Direct link to heading">​</a></h2><p>We're dissatisfied with our previous approach. Let's explore a lesser known Amazon S3 feature: <a href="https://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-HTTPPOSTConstructPolicy.html" target="_blank" rel="noopener noreferrer">POST Policy</a>.
You might be thinking, <em>"POST?, isn't it S3 PUT object?"</em>, and you're right, but Amazon actually introduced a POST API for uploading S3 objects to enable browser based S3 uploads.</p><p>As a note, you'll generally hear of POST Policy in the context of browser based uploads, but there's nothing inherent preventing us from using it in any environment.</p><p>A POST policy is essentially a JSON document that you create, sign, and return to your clients to specify what conditions are required for a successful POST object upload.</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="what-does-a-post-policy-look-like">What does a POST policy look like?<a class="hash-link" href="#what-does-a-post-policy-look-like" title="Direct link to heading">​</a></h4><p>POST policies are fairly powerful: you can specify the exact date time the policy expires and include conditions on properties like the <em>ACL</em>, <em>Bucket</em>, <em>Key prefix</em>,
and <em>Content length range</em> (minimum and maximum). You can also use operators like "starts_with" in addition to exact matches to add dynamic logic to your policy.</p><p>Let's take a look at an example POST policy.</p><div class="language-json codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-json codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token property" style="color:#36acaa">"expiration"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"2022-02-14T13:08:46.864Z"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token property" style="color:#36acaa">"conditions"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"> </span><span class="token property" style="color:#36acaa">"acl"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"bucket-owner-full-control"</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"> </span><span class="token property" style="color:#36acaa">"bucket"</span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"my-bucket"</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">"starts-with"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"$key"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"stuff/clientId"</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">"content-length-range"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">1048576</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">10485760</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>The policy results in the following conditions:</p><ul><li>The policy expires on Mon Feb 14 2022 13:08:46 UTC. After this time, any client using the policy to perform a POST upload will get a 403 error.</li><li>The ACL on the object must be <code>Bucket owner full control</code>, which ensures we, as the bucket owner, have full control of uploaded objects.</li><li>We specify a specific bucket by name (<code>my-bucket</code>) to allow uploads to.</li><li>The S3 key of the uploaded object must have a specific prefix. Here, we use it ensure our client only has permission to upload under their prefix by specifying their client ID as the key prefix.</li><li>The uploaded object must be between 1MB and 10MB in size.</li></ul><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="signing-the-policy">Signing the policy<a class="hash-link" href="#signing-the-policy" title="Direct link to heading">​</a></h4><p>After forming a POST policy, we have to <em>sign</em> the policy using valid IAM credentials (with the requisite permissions), similar to how we sign presigned URLs. You can view the
complete procedure on calculating the signature <a href="https://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-UsingHTTPPOST.html#sigv4-post-signature-calc" target="_blank" rel="noopener noreferrer">here</a> but it
essentially involves Base64 encoding the policy and signing it using AWS SigV4. Unfortunately, unlike presigned URLs, the AWS SDKs don't provide helper methods
to create the POST Policy. You can write it yourself or consult the few examples and community libraries out there. If you're using Java/JVM, check out
<a href="https://github.com/minio/minio-java/blob/master/api/src/main/java/io/minio/PostPolicy.java" target="_blank" rel="noopener noreferrer">Minio's implementation</a> as a well maintained reference.</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="letting-our-clients-perform-post-uploads">Letting our clients perform POST uploads<a class="hash-link" href="#letting-our-clients-perform-post-uploads" title="Direct link to heading">​</a></h4><p>Once we've created the POST policy, our client's can use the POST policy to perform POST S3 uploads. S3 POST uploads are multipart form data requests to the S3 Bucket URL
(e.g. <code>https://examplebucket.s3-us-west-2.amazonaws.com/</code>) containing the key's specified in the POST policy. As a code example in Python:</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> uuid </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> uuid</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> requests</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Add an endpoint for the client to request a POST Policy</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">post_policy_form_data </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> requests</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">get</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">"/postPolicyFormData"</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">post_policy_form_data </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">"x-amz-date"</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"20220213T233352Z"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">"x-amz-signature"</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"efa9bbc&lt;...&gt;"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">"acl"</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"bucket-owner-full-control"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">"x-amz-security-token"</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"&lt;...&gt;"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">"x-amz-algorithm"</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"AWS4-HMAC-SHA256"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">"x-amz-credential"</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"ASIA&lt;..&gt;."</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">"policy"</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"eyJleHBpcmF...&lt;base64 encoded policy&gt;"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token string" style="color:#e3116c">"Content-Type"</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"application/json"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">filename </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token builtin">str</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">uuid4</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">+</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">".json"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">key </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> os</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">path</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">join</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">"client_id"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> filename</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">content </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"file_content"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">multipart_form_data </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">**</span><span class="token plain">post_policy_form_data</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"key"</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> key</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"file"</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">filename</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> content</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">upload_url </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">"https://examplebucket.s3-us-west-2.amazonaws.com"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">res </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> requests</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">post</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">upload_url</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> files</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">multipart_form_data</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>POST policies satisfy all of our requirements.</p><ul><li>We are using signed policies without raw credentials.</li><li>Our clients can make HTTP requests without the AWS SDK.</li><li>We can granularly control the expiration, permissions, and object properties,</li><li>Our clients can upload objects as long as the POST policy is not expired without needing to make additional requests.</li></ul><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="conclusion">Conclusion<a class="hash-link" href="#conclusion" title="Direct link to heading">​</a></h2><p>We took a short look at the S3 object upload landscape, and discovered a powerful feature called POST Policies.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="usecases">Usecases<a class="hash-link" href="#usecases" title="Direct link to heading">​</a></h3><p>Lets take a look at some usecases that POST policies unlock:</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="browser-based-uploads">Browser based uploads<a class="hash-link" href="#browser-based-uploads" title="Direct link to heading">​</a></h4><p>Particularly for large sized files, POST policies provide a convenient way to enable your client's to upload files client side, without needing to go through a server proxy.
This can be convenient if you're using API Gateway or Lambda which have content size limits. Additionally, this can give your client better upload speed.</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="short-lived-low-latency-upload-sessions">Short lived low-latency upload sessions<a class="hash-link" href="#short-lived-low-latency-upload-sessions" title="Direct link to heading">​</a></h4><p>As we discussed, we can use POST policies to let our clients maintain a short lived, controlled session with specific permissions where they can upload many objects
of variable size, without any additional latency besides S3 latency.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="guidance">Guidance<a class="hash-link" href="#guidance" title="Direct link to heading">​</a></h3><p>As a takeway, if you are looking to incorporate S3 object upload from your clients in your application, follow the general guidance:</p><ul><li>Prefer presigned URLs. They're simpler, are already supported in the AWS SDKs and are well documented.</li><li>Use POST policies otherwise. As we discussed, if latency is important, or you want form based browser uploads.</li><li>Don't use the second approach we discussed (using <code>AssumeRole</code>). You can generally achieve the equivalent using a POST policy.</li></ul><p>Are you using POST policies, or do you know of an interesting usecase they enable? Feel free to reply.</p>]]></content>
        <author>
            <name>Samrose Ahmed</name>
            <email>samrose@matano.dev</email>
            <uri>https://matano.dev</uri>
        </author>
        <category label="engineering" term="engineering"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[What makes a good audit trail?]]></title>
        <id>/2022/02/05/what-makes-a-good-audit-trail</id>
        <link href="https://matano.dev/blog-archive/2022/02/05/what-makes-a-good-audit-trail"/>
        <updated>2022-02-05T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[At Apptrail, we obsess over audit trails and how to make them most valuable for our customers, so we thought we'd examine some real world examples of audit trails and see what makes some stand out from others.]]></summary>
        <content type="html"><![CDATA[<p>At Apptrail, we obsess over audit trails and how to make them most valuable for our customers, so we thought we'd examine some real world examples of audit trails and see what makes some stand out from others.</p><p>There's a lot of details and requirements that go into building an audit trails solution, from availability and immutability to
security and delivery, but, let's examine some of the features that differentiate solutions from one another.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="whats-an-audit-trail-anyway">What's an audit trail anyway?<a class="hash-link" href="#whats-an-audit-trail-anyway" title="Direct link to heading">​</a></h2><p><em>If you're already familiar with audit trails, feel free to skip this section.</em></p><p>An audit trail is a way to record user or API activity and surface that information. Generally, an audit trail lets admins or users
answer the <em>Who</em>, <em>When</em>, <em>Where</em>, and <em>What</em> of an action. Audit trails can be used to monitor suspicious activity
or replay activity in the aftermath of an event.</p><p>We use <em>audit trails</em>, <em>audit logs</em>, and <em>audit events</em> here interchangeably.</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="some-real-world-examples">Some real world examples<a class="hash-link" href="#some-real-world-examples" title="Direct link to heading">​</a></h2><p>Lets take a whirl through some popular tools that offer audit logs.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="google-admin">Google Admin<a class="hash-link" href="#google-admin" title="Direct link to heading">​</a></h3><p>Google Workspace has a mature audit logs offering. Let's see what we can do:</p><p><img loading="lazy" src="/assets/images/gadmin1-82647547805b5fba819d9c6619f8cece.png" width="1432" height="504" class="img_ev3q"></p><p>Immediately, we can see all the recent actions that took place with Google workspace.
The information contains the event name, description, time, who did the action (<em>actor</em>), and the IP address associated with the actor. The data is filterable and offers a CSV export through the UI. Google offers several types of audit logs, and data retention (how long the data is stored ranges from 6 to 15 months.</p><p>Google workspace audit log coverage is <a href="https://cloud.google.com/logging/docs/audit/gsuite-audit-logging#log-types" target="_blank" rel="noopener noreferrer">fairly extensive</a>, with both configuration changes and data access changes audited. Google also offers <a href="https://cloud.google.com/logging/docs/audit/configure-gsuite-audit-logs#api" target="_blank" rel="noopener noreferrer">an API</a> for accessing audit logs, and also enables <a href="https://cloud.google.com/logging/docs/audit/configure-gsuite-audit-logs#gcloud" target="_blank" rel="noopener noreferrer">streaming Google Audit logs into Google Cloud</a>.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="stripe">Stripe<a class="hash-link" href="#stripe" title="Direct link to heading">​</a></h3><p>Stripe uses logs in a few places. Let's take a look.</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="security-history">Security history<a class="hash-link" href="#security-history" title="Direct link to heading">​</a></h4><p><img loading="lazy" src="/assets/images/stripe1-bbc2ef7620b5aa3760c98ab8b8244714.png" width="1134" height="481" class="img_ev3q"></p><p>These events contain important actions, and similarly add information about the when, who, and where of the action.
The results are accessible in the Dashboard UI, and exportable to CSV.</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="request-logs">Request logs<a class="hash-link" href="#request-logs" title="Direct link to heading">​</a></h4><p>Stripe also offers developer oriented request logs. These are often used for debugging but are also essentially audit logs.</p><p><img loading="lazy" src="/assets/images/stripe2-eb6db5bd9019140a58eee0e445783115.png" width="1165" height="566" class="img_ev3q"></p><p>The Stripe request logs contain full request, response, and context data for every HTTP request
made to the API. They're viewable through the Stripe Dashboard UI and filterable on each dimension. Stripe request logs have a
15 month data retention period.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="github">Github<a class="hash-link" href="#github" title="Direct link to heading">​</a></h3><p>Github offers a pretty full featured <a href="https://docs.github.com/en/enterprise-cloud@latest/admin/user-management/managing-organizations-in-your-enterprise/streaming-the-audit-logs-for-organizations-in-your-enterprise-account" target="_blank" rel="noopener noreferrer">audit logs solution</a>
to its Enterprise customers. You can access Github audit logs by 1) using the web UI, 2) polling with the REST API, and 3) streaming to destinations like S3 or Splunk using
their audit log streaming feature.</p><p>Streaming audit logs is an important feature that a lot of audit logs solutions lack. It unlocks a lot of usecases, like being able to explore a large amount of data or retaining ownership over data, that a UI or API based approach don't allow.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="aws-cloudtrail">AWS CloudTrail<a class="hash-link" href="#aws-cloudtrail" title="Direct link to heading">​</a></h3><p>AWS offers audit logs for most of its services using <a href="https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-user-guide.html" target="_blank" rel="noopener noreferrer">CloudTrail</a>. You can query audit logs from the Console UI and using the AWS APIs. You can also deliver AWS audit logs to your S3 bucket or CloudWatch logs group. CloudTrail offers a pretty limited (heavily paginated and throttled) <a href="https://docs.aws.amazon.com/awscloudtrail/latest/APIReference/API_LookupEvents.html" target="_blank" rel="noopener noreferrer">LookupEvents</a> API to query audit data but in general nudges you towards sending audit logs to S3.</p><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="and-more">And more<a class="hash-link" href="#and-more" title="Direct link to heading">​</a></h3><p>There's many more software services offering audit logs. For the sake of brevity:</p><ul><li><a href="https://support.zendesk.com/hc/en-us/articles/4408828001434" target="_blank" rel="noopener noreferrer">Zendesk</a> offers audit logs through a UI, with filters, CSV export, and a REST query API. Logs
are retained for 1 year, which is not configurable.</li><li>1Password offers a UI based <a href="https://support.1password.com/activity-log/" target="_blank" rel="noopener noreferrer">activity log</a> with viewable and searchable activity including event, actor, and date, but omitting context such as IP. The activity log has a non configurable retention of 6 months.
Additionally, they offer a more extensive REST <a href="https://blog.1password.com/introducing-events-api/" target="_blank" rel="noopener noreferrer">Events API</a> for programmatic access and access to more audit events.</li></ul><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="comparison">Comparison<a class="hash-link" href="#comparison" title="Direct link to heading">​</a></h2><p>That covers a bit about audit trails, how customers use them, and what elements make them most useful to customers. Summarizing our survey:</p><table><thead><tr><th></th><th align="center">Filterable?</th><th align="center">Exportable?</th><th align="center">API access?</th><th align="center">Streaming?</th><th align="center">Configurable retention?</th></tr></thead><tbody><tr><td>Stripe</td><td align="center">✔️</td><td align="center">✔️</td><td align="center">❌</td><td align="center">❌</td><td align="center">❌</td></tr><tr><td>1Password</td><td align="center">✔️</td><td align="center">✔️</td><td align="center">✔️</td><td align="center">❌</td><td align="center">❌</td></tr><tr><td>Zendesk</td><td align="center">✔️</td><td align="center">✔️</td><td align="center">✔️</td><td align="center">❌</td><td align="center">❌</td></tr><tr><td>Google Workspace</td><td align="center">✔️</td><td align="center">✔️</td><td align="center">✔️</td><td align="center">✔️</td><td align="center">❌</td></tr><tr><td>Github</td><td align="center">✔️</td><td align="center">✔️</td><td align="center">✔️</td><td align="center">✔️</td><td align="center">✔️</td></tr><tr><td>CloudTrail</td><td align="center">✔️</td><td align="center">✔️</td><td align="center">✔️</td><td align="center">✔️</td><td align="center">✔️</td></tr></tbody></table><p>We can see audit trails vary on several dimensions:</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="self-service-access">Self service access<a class="hash-link" href="#self-service-access" title="Direct link to heading">​</a></h4><p>Admins being able to access the audit logs themselves, without needing a manual request, is the first step to a customer facing audit trail. At the bare minimum, a web UI to explore audit
logs should be provided.</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="exportability">Exportability<a class="hash-link" href="#exportability" title="Direct link to heading">​</a></h4><p>Viewing audit logs in a UI is good for one off usecases, but users often want to export the data for analysis with other tools.</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="programmatic-api-access">Programmatic API access<a class="hash-link" href="#programmatic-api-access" title="Direct link to heading">​</a></h4><p>Users want to be able to interact with their data programatically, for scripting, workflows, etc. The API should allow for querying events by time and filtering on fields. These APIs are generally paginated and throttled, as there is an unbounded number of audit logs.</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="audit-log-streaming">Audit log streaming<a class="hash-link" href="#audit-log-streaming" title="Direct link to heading">​</a></h4><p>When there's a large amount of audit logs, a poll based API is not sufficient, and users will want to have their data pushed into tools like S3 or Splunk, or other SIEM's or data analysis tools, for analysis.</p><h4 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="data-retention">Data retention<a class="hash-link" href="#data-retention" title="Direct link to heading">​</a></h4><p>Audit logs must be immutable to protect their integrity, but they are usually retained for a period of time, ranging from months to years. Ideally, this should be configurable by the user. Adding audit log streaming also automatically enables this, as it gives the customer ownership of their audit data (essentially unlimited retention).</p><h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="conclusion">Conclusion<a class="hash-link" href="#conclusion" title="Direct link to heading">​</a></h2><p>That was a short overview of some popular tools and how they offer audit trails to their customers.
We can see there are a range of different features that go into an audit logs solution, and software
providers vary in what they currently offer.</p><p>Do you have any examples of great audit logs? Feel free to share.</p>]]></content>
        <author>
            <name>Samrose Ahmed</name>
            <email>samrose@matano.dev</email>
            <uri>https://matano.dev</uri>
        </author>
        <category label="general" term="general"/>
    </entry>
</feed>